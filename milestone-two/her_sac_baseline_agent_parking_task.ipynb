{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "her-parking-task-highway-env.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.10 64-bit"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49e57814861f4eeca7c4907cc06c80da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e534d9ae9d649378dbd2554e78fc389",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1fa206e3b90d43f4a3d195d9cfa89163",
              "IPY_MODEL_6353b3800bbc4cf1b30c30e50d4979ab"
            ]
          }
        },
        "4e534d9ae9d649378dbd2554e78fc389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fa206e3b90d43f4a3d195d9cfa89163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_803cca0dbe6a461694019bc9f014e84f",
            "_dom_classes": [],
            "description": "Output Episodes: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14096f7b835948ef9f1767b872ad6df0"
          }
        },
        "6353b3800bbc4cf1b30c30e50d4979ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_12a47b61e0c14e589f2b22102c63901f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [01:32&lt;00:00, 18.47s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2943917459d94a0faa233214878b6deb"
          }
        },
        "803cca0dbe6a461694019bc9f014e84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14096f7b835948ef9f1767b872ad6df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12a47b61e0c14e589f2b22102c63901f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2943917459d94a0faa233214878b6deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBcj3aMxtjWb"
      },
      "source": [
        "### **Setting up the environment**\n",
        "\n",
        "* __Downgrading tensorflow for `stable-baselines` support.__\n",
        "* __Installing `highway-env` & `stable-baselines`.__\n",
        "* __Setting up virtual display for google colab.__\n",
        "* __Importing plotting and progress measurement packages.__\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOwH-ygkpqf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c6d15d-eead-46fa-873f-e8693d77a783"
      },
      "source": [
        "# Package download statements.\n",
        "# Note 1: This time we also use ffmpeg package for handling video recording related tasks.\n",
        "# Note 2: The package version are generic and doesn't require any specific package version downloads.\n",
        "!apt-get update >& /dev/null\n",
        "!pip install pyvirtualdisplay >& /dev/null\n",
        "!apt-get install -y xvfb python-opengl ffmpeg >& /dev/null\n",
        "!pip install highway_env\n",
        "# importing gym and high_env for loading different environment scenarios.\n",
        "import gym\n",
        "import highway_env\n",
        "\n",
        "# Agent related import statements.\n",
        "!pip install stable-baselines3\n",
        "# HER: stands for Hindsight Experience Replay, in stable-baselines it is a \n",
        "# wrapper package for algorithms like TD3, SAC, DDPG etc.\n",
        "\n",
        "# Note: HER works only on goal environment and works only gym env inherits from gym.GoalEnv.\n",
        "\n",
        "# SAC: stands for Soft Actor Critic, This algorithm optimizes stochastic policy\n",
        "# with off-policy approach. The policy is designed to maximize trade-off between\n",
        "# expected rewards and entropy i.e. randomness by this algorithm.\n",
        "from stable_baselines3 import HER, DQN, SAC, DDPG, TD3\n",
        "\n",
        "# tqdm: gives progress bars to loops.\n",
        "from tqdm.notebook import trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4g3K2OM4d7A"
      },
      "source": [
        "# Similar, to earlier rendering procedures for creating virtual display.\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "from gym.wrappers import Monitor\n",
        "from pathlib import Path\n",
        "import base64\n",
        "\n",
        "# Declaing display screen size for rendering highway-env environment.\n",
        "display = Display(visible=0, size=(1366, 768))\n",
        "display.start()\n",
        "\n",
        "# These functions are also available in '/highway-env/scripts/' directory in utils.py\n",
        "# file of highway-env github repository. These, can be directly accessed with below\n",
        "# commands but we are using these functions here to fix a specific size of recorded videos.\n",
        "# Note: commands are stated below for directly using these functions.\n",
        "# Also, we have changed these functions slightly. Therefore, refer documentation.\n",
        "\n",
        "# !git clone https://github.com/eleurent/highway-env.git\n",
        "# import sys\n",
        "# sys.path.insert(0, './highway-env/scripts/')\n",
        "# from utils import record_videos, show_videos, capture_intermediate_frames\n",
        "\n",
        "def wrap_env(env):\n",
        "    '''\n",
        "    Monitoring the environment interactions by agent and recording them in video.\n",
        "    '''\n",
        "    return Monitor(env, './video', force=True, video_callable=lambda episode: True)\n",
        "\n",
        "\n",
        "def show_video():\n",
        "    '''\n",
        "    Reading the stored video and display the output inline with code cells.\n",
        "    '''\n",
        "    html = []\n",
        "    for mp4 in Path('./video').glob(\"*.mp4\"):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append('''<video alt=\"{}\" autoplay\n",
        "                      loop controls style=\"height: 212px;\">\n",
        "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                 </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
        "\n",
        "\n",
        "def capture_intermediate_frames(env):\n",
        "    '''\n",
        "    Sending rendered frames to Monitor for logging video recording of captured frame.\n",
        "    '''\n",
        "    env.unwrapped.automatic_rendering_callback = env.video_recorder.capture_frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgd8gAaktnew"
      },
      "source": [
        "### **Model training for Soft Actor Critic (SAC) agent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AubtIyFo4lmz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b2b494e-4889-400b-ffd4-1a07a2fa7d46",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "env = gym.make(\"parking-v0\")\n",
        "\n",
        "# Stable-baselines3 needs max episode length to be set. \n",
        "\n",
        "# SAC parses the model class of Off-Policy RL model.\n",
        "# 'MlpPolicy' implements actor-critic with a MLP (2 layers of 64 nodes).\n",
        "model = HER('MlpPolicy', env, SAC, n_sampled_goal=4,\n",
        "            goal_selection_strategy='future', max_episode_length=100,\n",
        "            verbose=1, buffer_size=int(1e6),\n",
        "            learning_rate=1e-3,\n",
        "            gamma=0.95, batch_size=256, online_sampling=True,\n",
        "            policy_kwargs=dict(net_arch=[256, 256, 256]))\n",
        "# argument: total_timesteps is passed as approximately 33k.\n",
        "# It gives number of timestamps to train on.\n",
        "model.learn(int(32768))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-R1XRfXzUvK"
      },
      "source": [
        "# If you interested in saving the trained model.\n",
        "# Use 'save' function to save the model & 'load'\n",
        "# for loading model into memory.\n",
        "# model.save(\"./her_model_parking\")\n",
        "# We can also delete the existing model instance if we want to saved instance.\n",
        "# del model\n",
        "# model = HER.load('./her_model_parking', env=env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YQONSypuBzo"
      },
      "source": [
        "### **Displaying output for the trained SAC agent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUURKngd4d_D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "49e57814861f4eeca7c4907cc06c80da",
            "4e534d9ae9d649378dbd2554e78fc389",
            "1fa206e3b90d43f4a3d195d9cfa89163",
            "6353b3800bbc4cf1b30c30e50d4979ab",
            "803cca0dbe6a461694019bc9f014e84f",
            "14096f7b835948ef9f1767b872ad6df0",
            "12a47b61e0c14e589f2b22102c63901f",
            "2943917459d94a0faa233214878b6deb"
          ]
        },
        "outputId": "e3436b01-5d4d-4b10-fdbc-4a18f6ffa6db"
      },
      "source": [
        "env = wrap_env(gym.make(\"parking-v0\"))\n",
        "\n",
        "for episode in trange(5, desc=\"Output Episodes\"):\n",
        "    # capture_intermediate_frames is inside the loop\n",
        "    # With this we can capture multiple iterations of goal completion\n",
        "    # into our Monitor instance.\n",
        "    obs, done = env.reset(), False\n",
        "    capture_intermediate_frames\n",
        "\n",
        "    while not done:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "\n",
        "env.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUPPbInf4eCs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1041ec83-0681-4eed-8c1b-3f2d39aefc56"
      },
      "source": [
        "# Outputting all the goal completion videos.\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poA8rW0vuKWk"
      },
      "source": [
        "### **Downloading the created agent videos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzlyHGsBHWhq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "e96a860f-2bcf-420c-9193-8cc7cda697d6"
      },
      "source": [
        "# zipping the video folder for the given SARSA agent.\n",
        "!zip -r /content/file.zip /content/video\n",
        "# downloading the file resource.\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}